{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: InfluxDB\n",
    ".. index::\n",
    "   single: InfluxDB; Docker\n",
    ".. index::\n",
    "   single: Docker\n",
    ".. index::\n",
    "   single: Docker; InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfluxDB / Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we explain first the make-it-easy helper-script usage of InfluxDB time series database. In the second part we give necessary information for those who want to do the installation their way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: You are not obliged to run  InfluxDB time series database while underway - you can also stream all data into a so-called [Line Protocol File](../idbout/idbout.ipynb#Line-Protocol-File) which can be loaded into an InfluxDB DB back home. If only few data sources are needed, one can [record some data sources in a CSV-file with history graph instruments](../tactics/tactics.ipynb#Data-Export) for off-line analysis. But the provided helper script method based InfluxDB / Docker makes it so easy to use that you do not want to miss the new services which can be built around having near-term historical data - **all data** - at your disposal, like on Grafana dashboards."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: InfluxDB; Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Influx data](https://www.influxdata.com/)'s [InfluxDB 2.0](https://www.influxdata.com/products/influxdb-overview/influxdb-2-0/) is time series database which can be used directly for data analysis or used as a middleware for data analysis or monitoring software. A data streaming [connector](../idbout/idbout.ipynb#InfluxDB-Out) has been developed between _DashT_ for OpenCPN v5 plug-in and this popular time-series database platform. Most natural usage is to export **all** data received by the plug-in into Influx DB 2.0 with the millisecond time stamps of _DashT_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the all data is stored, it can be used to wide variety of usage, either immediately or extracted for off-line analysis. Here is an example of dashboards, familiar from Grafana but here provided by the InfluxDB 2.0 offering instant retrieval and analysis services for live data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_005_DashT_InfluxDB_Dashboard_and_3cells.png\"\n",
    "alt=\"InfluxDB dashboards\" width=\"500\">[(zoom)](img/005_DashT_InfluxDB_Dashboard_and_3cells.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: InfluxDB; Scripts\n",
    ".. index::\n",
    "   single: Docker; Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker ([Docker Desktop](https://www.docker.com/products/docker-desktop) for Windows and Mac) is a popular framework to containerize applications. Shortly, a \"container\" is a mini-operating system, often Linux based running one single service, usually network based. The container is running under Docker or Docker desktop and you would communicate with the application over the network. The application can be made to see your file system so that you can share data with it without going through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: Why there is no _DashT_ Docker container? Simply because it would make yet another build to maintain and yet another dependency. Instead, standard and latest service containers can be used and configuration scripts for those are provided with _DashT_ installation package and explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**TIP**: You can try and *not* to stop InfluxDB using the helper scripts below when you stop your system; normally, at next restart Docker will restart all the services. But on Windows systems, do not leave your system too long time off, without restarting the InfluxDB using the provided script - it synchronizes the clock only this way on Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper scripts to start and stop the Docker based InfluxDB, Grafana and nginx web server are provided with _DashT_. The supporting configuration files are installed in `\\Users\\Public\\DashT` folder. Two buttons are installed on the Desktop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start DB (database _and_ web services)\n",
    "1. Stop DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All you need to do to make the buttons work is to **install** yourself [Docker Desktop](https://www.docker.com/products/docker-desktop) and **start it** - following the _DashT_ maxim _\"if you do not want it, you will not get it\"_, no third party software is installed by _DashT_ installer so that you can keep the control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: the helper scripts have been developed and tested for Docker Desktop v3.3.3. By default the latest InfluxDB is installed, while the tests have been carried out with InfluxDB v2.0.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**TIP**: If Docker Desktop announces that our system is **Hyper-V compatible** (Windows 10 Pro only) but suggests to use [WSL 2](https://devblogs.microsoft.com/commandline/announcing-wsl-2/) it is not recommended for these applications: InfluxDB, Grafana and nginx will all have part of their filesystems mapped back to local Windows file system in the Public folder. This has been reported to work in less optimal way and even a warning about it given by Docker Desktop v3.3.3. **Hyper-V is preferable here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linux scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Linux version of the above is the helper script _**dashtdb**_ - you would use it from the command line:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "you@yourlinux:~$ dashtdb\n",
    "\n",
    "dashtdb - Launching Docker based services for DashT: nginx, infludb, grafana\n",
    "Usage:\n",
    "      dashtdb [start|up]\n",
    "      dashtdb [stop|down]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: we let fans of GNOME3, KDE, LXQT, xfce4 and alike to create their own desktop buttons!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same way, like on the Windows counterpart the principle _\"only if you want it you will get it\"_ is respected; no third party software is declared as automatic dependency in the _DashT_ package installation. Only if you launch the `dashtdb` script and if the supporting software is not there, you will be asked do you want to get it installed. This way, a person who is not interested in database functions will not get database software installed for nothing.\n",
    "\n",
    "Third-party programs installed by the script - with your permission:\n",
    "\n",
    "- dashtdb script needs:\n",
    "  - docker, docker-compose\n",
    "    - InfluxDB v2.0, Grafana, nginx web server"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: InfluxDB; Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no reason to repeat [InfluxDB v2.0 documentation](https://v2.docs.influxdata.com/v2.0/) here. But setting up the database for your boat is dead easy already from the welcome screen of InfluxDB 2.0, which is now at `http://127.0.0.1:9999 `, or in `http://host.docker.internal:9999` if you prefer. The guidance for the first time configuration is excellent! You will need to give:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User name and password\n",
    "- Organization name - like the name of your boat\n",
    "- \"Bucket\" name - this is where the data is going to be dropped into, give it a name like \"nmea\", why not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan not to use streaming or reading back of data, just file-based data storage when underway and its feeding into the database when back in the safe harbour, you are done. You would use, later on this very same interface to upload the data file into the database, into the bucket you have created. Database service itself does not need to run, in this case when you are underway, _DashT_ [InfluxDB Out](../idbout/idbout.ipynb#InfluxDB-Out) is enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, streaming data in live into the database and reading it back live requires a token (your username and password are never asked in data communication):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_010_DashT_InfluxDB_Tokens.png\"\n",
    "alt=\"InfluxDB setting a token\" width=\"400\">[(zoom)](img/010_DashT_InfluxDB_Tokens.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give the token in [InfluxDB Out](../idbout/idbout.ipynb#HTTP-Streamout) instrument's configuration to enable HTTP-based real-time write/read operations between _DashT_ and InfluxDB v2. You would need to keep the database container running, in this case when underway."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: InfluxDB; Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InfluxDB storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this solution with Docker, with _DashT_ configuration scripts data is stored on your computer, the same one which is hosting Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Windows**: `C:\\Users\\Public\\DashT\\influxdb2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linux**: `~/.opencpnplugins/dashboard_tactics_pi/instrujs/influxdb2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to back up or otherwise keep these directories safe if you want to keep long-term archives of the data. _DashT_ cannot guarantee the integrity of the data since this directory is totally under control of Docker/InfluxDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: On Linux you can relink this directory to an external device, such as USB3-connected disk to reduce the load to your system disk against repetitive small chunks of writes (if your system disk a semiconductor storage device) and for backup purposes. (On Windows, Docker will most likely have no permission to write to the device which is out of Public or user's folders.)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: nginx; HTML/JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML/JS updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML and JavaScript for the Engine/Energy and other web based instruments are available, in default _nginx_ configuration in port `8088`. This way, you do not need necessarily run a specific server on port `8080` for Engine and Energy instruments using its [own helper script](../enginedjg/enginedjg.ipynb#Engine-Gage-script). Of course, you need to change the port also in the configuration file of OpenCPN, see [Tweaks](../tweaks/tweaks.ipynb#DashT/WebView)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Windows**: Update of _DashT_ (_i.e._ reinstalling with installation `.exe` updates the folder `C:\\Users\\Public\\DashT\\www` from where the _ngingx_ is serving the HTML/JS files for the instruments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Linux**: Update of _DashT_ does **not update HTML/JS files** in `~/.opencpnplugins/dashboard_tactics_pi/instrujs/www` - they are copies of the distribution's files. After an update of _DashT_, it is enough to remove the folder `www` in the above user path and launch the `dashtdb` scripts, which will recreate the folder and copy the updated HTML and JavaScript files into it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: Docker; Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section you may want to read only when things do not work for you, for simple curiosity or if you want to do the things yourself - maybe you have a Mac and the above scripts are not available for you (but you can maybe contribute by modifying the Linux scripts as a starting point)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: Docker; Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_015_DashT_Docker_Dashboard_3_services.png\"\n",
    "alt=\"Docker - Dashboard - 3 services running\" width=\"200\">[(zoom)](img/015_DashT_Docker_Dashboard_3_services.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Docker Desktop's Dashboard to view the three containers created by the above helper scripts, providing three useful services:\n",
    "\n",
    "* **nginx** - this is the HTTP / proxy server, a Swiss knife providing both files to OpenCPN's _DashT_ but also connecting it to other network based services, and interconnecting those services\n",
    "* **InfluxDB v2** - time series database which both collects data from DashT but which is also available to feed it back to _DashT_ but also to other useful services:\n",
    "* **Grafana** - A monitoring solution which allows you to create more complex dashboards that would be possible with _DashT_ or with _InfluxDB v2_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: We do not run a _Signal K server node_ in Docker - it may require some physical connection like USB and it is better done with _Node.js_ which is also network performance-wise a better solution than running it in a Docker instance. For testing and learning purposes it is, of course, possible to run Signal K as a Docker instance as well."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: Docker; command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command line is the same both for Linux or Windows (and probably for Mac):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`you@yourlinux:~$ docker container ls`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_020_DashT_Docker_ls_output.png\"\n",
    "alt=\"Docker - ls-command\" width=\"700\">[(zoom)](img/020_DashT_Docker_ls_output.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: Docker; composer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Containers are created using the following type of container definition (example from Windows, in Linux version only the file system mount points do change), the file is named in both `docker-compose.yml`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "version: '3'\n",
    "services:\n",
    "  web: \n",
    "    image: nginx:latest\n",
    "    container_name: dasht_nginx\n",
    "    depends_on:\n",
    "      - db\n",
    "    volumes:\n",
    "      - /c/Users/Public/DashT/nginx/nginx.conf:/etc/nginx/nginx.conf\n",
    "      - /c/Users/Public/DashT/www:/data/www\n",
    "    ports:\n",
    "      - 8088:80\n",
    "      - 8089:8089\n",
    "  graphs:\n",
    "    image: grafana/grafana:latest\n",
    "    container_name: dasht_grafana\n",
    "    depends_on:\n",
    "      - db\n",
    "    links:\n",
    "      - db\n",
    "    volumes:\n",
    "      - /c/Users/Public/DashT/grafana:/var/lib/grafana\n",
    "    ports:\n",
    "      - 30000:3000\n",
    "  db: \n",
    "    image: quay.io/influxdb/influxdb:2.0.0-beta\n",
    "    container_name: dasht_influxdb\n",
    "    volumes:\n",
    "      - /c/Users/Public/DashT/influxdb2:/var/lib/influxdb2\n",
    "    command: influxd run --bolt-path /var/lib/influxdb2/influxd.bolt\n",
    "    --engine-path /var/lib/influxdb2/engine --store bolt --reporting-disabled\n",
    "    ports:\n",
    "      - 9999:8086\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description files define all the steps that one would need to either to type manually or set up using Docker Desktop. Now it is automatic every time you use the _DashT_ stop/start scripts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: On Windows systems, the start-up scripts of _DashT_ also synchronize the InfluxDB container's clock with the local CPU clock. This is needed because on Windows, the clock is provided by Hyper-V virtualization. And when you are not running any containers that clock is not running... For this reason, it is extremely important to synchronize your CPU time to a reliable data source (like GPS, when underway)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe that both network ports, dependencies and mount points in local file system have been defined. If you need or want to do the work manually, the above description can be used as a starting point for what is needed."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: nginx\n",
    ".. index::\n",
    "   single: Docker; nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[nginx](http://nginx.org/en/) _engine x_ is an HTTP and reverse proxy server. It is a true Swiss knife, allowing us to provide and share all services local, like http://localhost:8088 - we need more services, we just add port numbers. With _nginx_'s rirch features and high its reverse proxy we can\n",
    "\n",
    "* Make _DashT_ network based files available as network service from the local file system, the same in which OpenCPN is installed - no copying is needed\n",
    "* We can make the code in those files to access _InfluxDB v2_ **in parallel** with your browser and with _Grafana_ by enabling [CORS](https://en.wikipedia.org/wiki/Cross-origin_resource_sharing) (_Cross-Origin-Resource-Sharing_) so that browser security features gets satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: without a CORS-enabling proxy it is impossible for a web-based application like JavaScript instruments of _DashT_ to read/write into InfluxDB or other web service since they are not originating from that very same web service. However, [InfluxDB Out](../idbout/idbout.ipynb#InfluxDB-Out) is not affected by this so if you do not use JavaScript instruments, you can omit the CORS-enabling proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want _nginx_ to configure two local port, to act as proxy server and to deal with CORS so that the localhost served JavaScript files can access services such as the _InfluxDB v2_ - same thing for Grafana, let it access _InfluxDB v2_ :\n",
    "\n",
    "* port 8088 - is mapped in Docker container as port 80, bind back to the host's local file system so that _DashT_ provided `www` directory (instrument HTML5/JavaScript) can be served\n",
    "* port 8089 - is a proxy for files served from 8088 wanting to access _influxdb_ server - [CORS Access Control headers](https://en.wikipedia.org/wiki/Cross-origin_resource_sharing#How_CORS_works) are replied to browsers confirming them that this is OK - tested Chrome 80, Firefox 74 and even IE11 (because WebView of wxWidgets is using it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "user  nginx;\n",
    "worker_processes  1;\n",
    "\n",
    "error_log  /var/log/nginx/error.log warn;\n",
    "pid        /var/run/nginx.pid;\n",
    "\n",
    "\n",
    "events {\n",
    "    worker_connections  1024;\n",
    "}\n",
    "\n",
    "\n",
    "http {\n",
    "    include       /etc/nginx/mime.types;\n",
    "    default_type  application/octet-stream;\n",
    "\n",
    "    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n",
    "                      '$status $body_bytes_sent \"$http_referer\" '\n",
    "                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n",
    "\n",
    "    access_log  /var/log/nginx/access.log  main;\n",
    "\n",
    "    sendfile        on;\n",
    "    #tcp_nopush     on;\n",
    "\n",
    "    keepalive_timeout  65;\n",
    "\n",
    "    #gzip  on;\n",
    "    \n",
    "    server {\n",
    "      listen 80;\n",
    "      location / {\n",
    "        root /data/www;\n",
    "        autoindex on;\n",
    "      }\n",
    "    }\n",
    "    server {\n",
    "      listen 8089;\n",
    "      # https://enable-cors.org/server_nginx.html\n",
    "      location / {\n",
    "        # InfluxDB query, read\n",
    "        if ($request_method = 'OPTIONS') {\n",
    "            add_header 'Access-Control-Allow-Credentials' 'true' always;\n",
    "            add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';\n",
    "            add_header Access-Control-Allow-Origin $http_origin;\n",
    "            add_header 'Access-Control-Allow-Headers'\n",
    "            'Authorization,Accept,Origin,DNT,User-Agent,X-Requested-With,\n",
    "            If-Modified-Since,Cache-Control,Content-Type,Range';\n",
    "            add_header 'Access-Control-Expose-Headers' 'Content-Length,Content-Range';\n",
    "            #\n",
    "            # Tell client that this pre-flight info is valid for 20 days\n",
    "            #\n",
    "            add_header 'Access-Control-Max-Age' 1728000;\n",
    "            add_header 'Content-Type' 'text/plain; charset=utf-8';\n",
    "            add_header 'Content-Length' 0;\n",
    "            return 204;\n",
    "        }\n",
    "        # InfluxDB query, write\n",
    "        if ($request_method = 'POST') {\n",
    "            add_header 'Access-Control-Allow-Credentials' 'true' always;\n",
    "            add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';\n",
    "            add_header 'Access-Control-Allow-Headers' \n",
    "            'Authorization,Accept,Origin,DNT,User-Agent,X-Requested-With,\n",
    "            If-Modified-Since,Cache-Control,Content-Type,Range';\n",
    "            add_header 'Access-Control-Expose-Headers' 'Content-Length,Content-Range';\n",
    "        }\n",
    "        if ($request_method = 'GET') {\n",
    "            add_header 'Access-Control-Allow-Credentials' 'true' always;\n",
    "            add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';\n",
    "            add_header 'Access-Control-Allow-Headers'\n",
    "            'Authorization,Accept,Origin,DNT,User-Agent,X-Requested-With,\n",
    "            If-Modified-Since,Cache-Control,Content-Type,Range';\n",
    "            add_header 'Access-Control-Expose-Headers' 'Content-Length,Content-Range';\n",
    "        }\n",
    "        proxy_redirect off;\n",
    "        proxy_set_header host $host;\n",
    "        proxy_set_header X-real-ip $remote_addr;\n",
    "        proxy_set_header X-forward-for $proxy_add_x_forwarded_for;\n",
    "        proxy_pass http://host.docker.internal:9999;\n",
    "      }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: To read InfluxDB v2.0 database, the client shall use OPTIONS-method, not GET-method which will be rejected. Therefore the CORS-proxy function is implemented only for OPTIONS-method. It is noteworthy also that [InfluxDB Out](../idbout/idbout.ipynb#HTTP-Streamout) will not need to go through the proxy, it can POST directly the data into the TCP/IP port 9999 of the server. But if a JavaScript client needs to do the same, it needs to go through this proxy and the POST-options needs to be implemented with the CORS-proxy functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is nice to be able edit directly the _nginx_'s configuration file without sometimes complicated tricks. That's why we bind it to a local file system file as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**TIP**: In Windows Docker Desktop 3.3.3. we use `proxy_pass http://host.docker.internal:9999` instead of `proxy_pass http://dasht_influxdb:9999`: while the name resolving worked in earlier versions, in this version one needs to refer to Docker host which then resolves the address. Otherwise a 502 bad gateway error will be returned by ngingx in this configuration."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: Grafana\n",
    ".. index::\n",
    "   single: Docker; Grafana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Grafana](https://grafana.com) is an open source analytics and monitoring solution for almost every database based data, including _InfluxDB v2.0_. _DashT_ bundles this popular and easy-to-use visualization solution it in its Docker ready-to-launch configuration albeit it does not use it, in any way in _OpenCPN_. For your convenience, _DashT_ sets up you few essentials needed to work both with Docker and with a InfluxDB v2 container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With _Grafana_ we want to use a separated volume to share it settings and other parameters in persistent manner, provided that we need to delete and restart the container. The volume is located in local file system as defined in `docker-compose.yml` (see above)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: Grafana; Flux\n",
    ".. index::\n",
    "   single: Grafana; Data Source "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: To help with the data retrieval from the InfluxDB v2 time series database, _DashT_ Docker helper scripts are installing in the mounted, local file system for Grafana, in its `plugins` folder _InfluxDB (Flux) Datasource_ (`grafana-influxdb-flux-datasource`) to make the data retrieval possible by a simply data source selection."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: Grafana; Ports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafana needs two network connections now: one to talk with you (or rather with your browser). All the settings are done in the above configuration file but perhaps it is more clear to look at the resulting container settings with Docker: `docker inspect dasht_grafana`: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "            \"Ports\": {\n",
    "                \"3000/tcp\": [\n",
    "                    {\n",
    "                        \"HostIp\": \"0.0.0.0\",\n",
    "                        \"HostPort\": \"30000\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the port Grafana is listening. Point your browser, in this case to `http://localhost:30000` (chosen not to get mixed with _Signal K server node_ port 3000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second interface is to Docker: please Docker, let me talk to the InfluxDB database container... Again, this is set in the above configuration file as `db` link, but let's see what Docker reports about in with the above `docker inspect` command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "            \"Networks\": {\n",
    "                \"dasht_default\": {\n",
    "                    \"IPAMConfig\": null,\n",
    "                    \"Links\": [\n",
    "                        \"dasht_influxdb:dasht_influxdb\",\n",
    "                        \"dasht_influxdb:db\"\n",
    "                    ],\n",
    "                    \"Aliases\": [\n",
    "                        \"graphs\",\n",
    "                        \"e965d09373b1\"\n",
    "                    ],\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, in Grafana container we can reach the neighbouring InfluxDB v2 container either with a URL `http://dasht_influxdb:9999` or with its alias `http:://db:9999`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make confusion total, the newer version of Docker Desktop 3.x requires a pseudo host name `http://host.docker.internal:9999`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with this knowledge, we can configure Grafana's _InfluxDB (Flux) Datasource_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: (When this is written May 2021) Grafana's InfuxDB  data source plug-in says that Flux support is stil in beta. Therefore we use Influx's own (beta) which DashT installs by default. The situation is likely to change, hopefully the interface will not change too much and the below remains applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_025_DashT_Grafana_Flux_data_source.png\"\n",
    "alt=\"Grafana - data source Flux\" width=\"500\">[(zoom)](img/025_DashT_Grafana_Flux_data_source.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the settings you need to collect from InfluxDB v2 (you can have another tab/window open in http://localhost:9999):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_030_DashT_Grafana_Flux_cnx_details.png\"\n",
    "alt=\"Grafana - data source Flux cnx details\" width=\"300\">[(zoom)](img/030_DashT_Grafana_Flux_cnx_details.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use the default URL, like `http://127.0.0.1:9999' to connect to InfluxDB v2, you will get an error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_035_DashT_Grafana_Flux_cnx_bad_gtw.png\"\n",
    "alt=\"Grafana - data connecion error bad gateway\" width=\"250\">[(zoom)](img/035_DashT_Grafana_Flux_cnx_bad_gtw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or similar, depending of the Docker Desktop version you are using (2.x or 3.x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to access the InfluxDB v2 through the Docker provided container-to-container link. _DashT_ script has given it an alias `db` (of course!). Port remains the same `9999` (we are not going through the proxy server.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Docker Desktop 2.x**: Give URL `http://db.9999`, the alias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Docker Desktop 3.x**: Give URL `http://host.docker.internal:9999`, which then translates in Docker as 'local host'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_040_DashT_Grafana_Flux_cnx_use_db_9999.png\"\n",
    "alt=\"Grafana - data connection URL\" width=\"250\">[(zoom)](img/040_DashT_Grafana_Flux_cnx_use_db_9999.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_045_DashT_Grafana_Flux_cnx_use_db_9999_test_OK.png\"\n",
    "alt=\"Grafana - data connection test\" width=\"250\">[(zoom)](img/045_DashT_Grafana_Flux_cnx_use_db_9999_test_OK.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some data now and some Flux code to request for it. Let's first collect some data in InfluxDB. Here we select TWS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_050_DashT_Grafana_InfluxDB_get_TWS.png\"\n",
    "alt=\"InfluxDB - collect some TWS data\" width=\"700\">[(zoom)](img/050_DashT_Grafana_InfluxDB_get_TWS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not familiar with Flux language (who is?) one can easily get a good example with the InfluxDB Script Editor, here for the above screen, one just switches from the click-based selection for inquiry builder to the Script Editor in the above example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: there are variables used by InfluxDB which one cannot copy as such to the other program, such as Grafana. We need to remove those and either use Grafana's variable or avoid using them. Here's the code with only one variable in Grafana, `n` for the limit of the samples to collect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from(bucket: \"nmea\")\n",
    "  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"environment\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"wind\")\n",
    "  |> filter(fn: (r) => r[\"prop1\"] == \"speedTrueGround\")\n",
    "  |> movingAverage(n: 20)\n",
    "  |> aggregateWindow(every: v.windowPeriod, fn: mean, createEmpty: false)\n",
    "  |> yield(name: \"mean\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code has been generated in the _InfluxDB Explorer_ and it can be cut and pasted to _Grafana Dashbaord_. It is used, almost the same but with shorted sliding time in the _DashT_ instrument [Line Chart](../linechart/linechart.ipynb#Line-Chart)). You can therefore make your choice for the presentation tool, the data and its retrieval remains the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Grafana_ provides all sorts of debugging tools, such as Query Inspector which are extremely helpful if something goes wrong. It is unfortunately impossible to rewrite here all the knowledge one can certainly find in _Grafana_ documentation or just by trying things out. _Grafana_ is some pretty powerful piece of software, which is used for Data Center management etc. so do not get frustrated too quickly but experiment. Some nice winter fun!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: Grafana; Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_055_DashT_Grafana_InfluxDB_get_TWS_Flux.png\"\n",
    "alt=\"Grafana - paste some Flux code copied from InfluxDB\" width=\"700\">[(zoom)](img/055_DashT_Grafana_InfluxDB_get_TWS_Flux.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you have a big screen in your boat, nothing prevents to put you tens of graphical instruments on it's mighty real estate area. In this example there is only one humble Grafana dashboard instrument:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/s_060_DashT_Grafana_Dashboard_TWS_Flux.png\"\n",
    "alt=\"Grafana - Dashboard with single TWS graph\" width=\"700\">[(zoom)](img/060_DashT_Grafana_Dashboard_TWS_Flux.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: InfluxDB; Developer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InfluxDB read-back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While [Grafana](#Grafana) is the suggested dashboard tool for on-board and on-line usage of data, the InfluxDB API provides multiple possibilities for developers for on-line and off-line data retrieval for further analysis. While the development details are out of the scope of this document, we can list the following links for those who are interested to get more information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* JavaScript/TypeScript: DashT [Line Chart](../linechart/linechart.ipynb#Line-Chart) is a Grafana-wannabe line history drawing instrument using InfluxDB's TypeScript API to retrieve the data. You can find the corresponding module [here](https://github.com/canne/dashboard_tactics_pi/blob/8e2074f996d8c2c43028a440cdb4cc77a801f862/instrujs/timestui/src/idbclient.ts)\n",
    "* Python Panda DataFrames are most convienent to analyze and plot the data off-line. Please see [this folder in the development repository](https://github.com/canne/dashboard_tactics_pi/tree/8e2074f996d8c2c43028a440cdb4cc77a801f862/docs/developers/influxdb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: nginx; Troubleshooting\n",
    ".. index::\n",
    "   single: Troubleshooting; nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troubleshooting is done best with _nginx_ server using an ordinary browser, by attempting to open the aforementioned ports 8088 (you would expect to find _DashT_ JavaScript instrument's home directory to load the HTML5/JavaScript code) and port 8089 (with InfluxDB v2 running on port 9999 you would expect to drop on it's login page)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All browsers contain debug tools, for example if you want to open any _DashT_ JavaScript instrument's `index.html` page you can get good information in case of eventual issues with the page loading like that. Please see the [troubleshoot section of EngineDJG](../enginedjg/enginedjg.ipynb#After-config,-all-dead)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: Docker; Attach console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you do not get connected anywhere, it would be worthwhile to open a console on the Docker container which is providing the _nginx_ service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**NOTE**: On **Windows**, you may have left the services running when shutting down, in which case the containers are started automatically. However, one cannot connect to them with Docker tools unless you have also _Docker Desktop_ running. This, you may have selected not to start automatically. If this is the case you need to start it now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**TIP**: On Docker Desktop for Windows one has a button `Logs` which allows to see similar information as below in case one does not like the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check first that you have, indeed the containers still running:\n",
    "```\n",
    "docker container ls\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From command line, attach the console to the _dasht_nginx_ container:\n",
    "```\n",
    "docker container attach dasht_nginx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to reach the above connections (ports) again and observe the console. It should say, if working correctly access to all ports (or error messages if an issue):\n",
    "```\n",
    "172.20.0.1 - - [07/Sep/2020:09:54:59 +0000] \"GET / HTTP/1.1\" 200\n",
    "1301 \"-\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36\n",
    "(KHTML, like Gecko) Chrome/85.0.4183.106 Safari/537.36\" \"-\"\n",
    "172.20.0.1 - - [07/Sep/2020:09:55:00 +0000] \"GET /favicon.ico\n",
    "HTTP/1.1\" 200 1150 \"http://localhost:8088/\" \"Mozilla/5.0 (Windows\n",
    "NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko)\n",
    "Chrome/85.0.4183.106 Safari/537.36\" \"-\"\n",
    "172.20.0.1 - - [07/Sep/2020:09:55:04 +0000] \"GET\n",
    "/orgs/59f148cfc72908cc HTTP/1.1\" 200 313 \"-\" \"Mozilla/5.0 (Windows\n",
    "NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko)\n",
    "Chrome/85.0.4183.106 Safari/537.36\" \"-\"\n",
    "172.20.0.1 - - [07/Sep/2020:09:55:04 +0000] \"GET /5e93c5f5aa.js\n",
    "HTTP/1.1\" 304 0 \"http://localhost:8089/orgs/59f148cfc72908cc\"\n",
    "\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML,\n",
    "like Gecko) Chrome/85.0.4183.106 Safari/537.36\" \"-\"\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the console attachment with `Ctrl-P` `Ctrl-Q` key-combination - this way the container will continue running. To get back to command prompt after this, use `Ctrl-C` as usual."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. index::\n",
    "   single: Grafana\n",
    ".. index::\n",
    "   single: Docker; Grafana"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
